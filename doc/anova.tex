\documentclass[12pt]{article}
\usepackage{amsmath}
\parindent=0pt
\begin{document}

Consider the following anova program and its output.
Note that the least significant difference test has more power than the $t$-test.

{\scriptsize\begin{verbatim}
data ;
input trt $ y @@ ;
datalines ;
A 6    A 0    A 2    A 8   A 11
A 4    A 13   A 1    A 8   A 0
B 0    B 2    B 3    B 1   B 18
B 4    B 14   B 9    B 1   B 9
C 13   C 10   C 18   C 5   C 23
C 12   C 5    C 16   C 1   C 20
;

proc anova ;
model y = trt ;
means trt / lsd ttest ;
\end{verbatim}}

{\scriptsize\begin{verbatim}
                              Analysis of Variance

    Source     DF     Sum of Squares      Mean Square     F Value     Pr > F
    Model       2       293.60000000     146.80000000        3.98     0.0305
    Error      27       995.10000000      36.85555556                       
    Total      29      1288.70000000                                        

                R-Square     Coeff Var     Root MSE       Y Mean
                0.227826     76.846553     6.070878     7.900000

     Source     DF         Anova SS      Mean Square     F Value     Pr > F
     TRT         2     293.60000000     146.80000000        3.98     0.0305

                                 Mean Response

             TRT      N        Mean Y     95% CI MIN     95% CI MAX
             A       10      5.300000       1.360937       9.239063
             B       10      6.100000       2.160937      10.039063
             C       10     12.300000       8.360937      16.239063

                       Least Significant Difference Test

  TRT    TRT      Delta Y    95% CI MIN    95% CI MAX    t Value    Pr > |t|  
  A      B      -0.800000     -6.370677      4.770677      -0.29      0.7705  
  A      C      -7.000000    -12.570677     -1.429323      -2.58      0.0157 *
  B      A       0.800000     -4.770677      6.370677       0.29      0.7705  
  B      C      -6.200000    -11.770677     -0.629323      -2.28      0.0305 *
  C      A       7.000000      1.429323     12.570677       2.58      0.0157 *
  C      B       6.200000      0.629323     11.770677       2.28      0.0305 *

                               Two Sample t-Test

  TRT    TRT      Delta Y    95% CI MIN    95% CI MAX    t Value    Pr > |t|  
  A      B      -0.800000     -5.922307      4.322307      -0.33      0.7466  
  A      C      -7.000000    -12.664270     -1.335730      -2.60      0.0182 *
  B      A       0.800000     -4.322307      5.922307       0.33      0.7466  
  B      C      -6.200000    -12.467653      0.067653      -2.08      0.0523  
  C      A       7.000000      1.335730     12.664270       2.60      0.0182 *
  C      B       6.200000     -0.067653     12.467653       2.08      0.0523  
\end{verbatim}}

\newpage

Let us take a closer look at the analysis of variance table.

{\scriptsize\begin{verbatim}
                              Analysis of Variance

    Source     DF     Sum of Squares      Mean Square     F Value     Pr > F
    Model       2       293.60000000     146.80000000        3.98     0.0305
    Error      27       995.10000000      36.85555556                       
    Total      29      1288.70000000
\end{verbatim}}

This is how the table values are computed where $n$ is the number of observations
and $p$ is the number of model parameters.

{\scriptsize\begin{center}\begin{tabular}{lccccc}
Source & DF & Sum of Squares & Mean Square & $F$-value & $p$-value
\\
Model
& $p-1$
& SSR
& $\text{MSR}=\text{SSR}/(p-1)$
& $F^*=\text{MSR}/\text{MSE}$
& $1-F(F^*,p-1,n-p)$\\
Error
& $n-p$
& SSE
& $\text{MSE}=\text{SSE}/(n-p)$
& &\\
Total
& $n-1$
& SST
& & &
\end{tabular}\end{center}}

For the following sum of squares calculations, $y$ are observed values and $\hat y$ are predicted values.
\begin{align*}
\text{SSR}&=\sum(\hat y_i-\bar y)^2
\\
\text{SSE}&=\sum(y_i-\hat y_i)^2
\\
\text{SST}&=\sum(y_i-\bar y)^2
\end{align*}

%Recall that MSE is an estimate of model variance.
%\begin{equation*}
%\text{MSE}=\frac{\text{SSE}}{n-p}=\hat\sigma^2
%\end{equation*}

The $p$-value in the anova table is used for checking that the regression model
is better than the mean $\bar y$.
The null hypothesis is that the model is no better than the mean, that is
\begin{equation*}
H_0:\text{SSE}=\text{SST}
\end{equation*}

%The test for $H_0$ is known as an omnibus test because an
%equivalent hypothesis is that all of the model parameters are zero.
%\[
%H_0:\beta_1=\beta_2=\cdots=\beta_{p-1}=0
%\]

Under $H_0$ we have $\text{SSR}=0$ hence $\text{MSR}=0$ and
\begin{equation*}
H_0:F^*=0
\end{equation*}

%The test statistic $F^*$ is used because it has a well-known distribution, i.e., the $F$-distribution.
Recall that the $p$-value is (loosely) the probability that $H_0$ is true.
Hence for small $p$-values, reject $H_0$ and conclude that the regression model is better than the mean.

\newpage

Let us take a closer look at the mean response table.

{\scriptsize\begin{verbatim}
                                 Mean Response

             TRT      N        Mean Y     95% CI MIN     95% CI MAX
             A       10      5.300000       1.360937       9.239063
             B       10      6.100000       2.160937      10.039063
             C       10     12.300000       8.360937      16.239063
\end{verbatim}}

Recall that the confidence interval for a treatment mean is
\begin{equation*}
\bar y\pm t(1-\alpha/2,\text{dfe})\times\text{SE},
\quad
\text{SE}=\sqrt{\frac{\text{MSE}}{n}}
\end{equation*}
where SE is standard error and MSE (mean square error) is estimated model variance.
From the analysis of variance table at the top of the output we have

{\scriptsize\begin{verbatim}
    Source     DF     Sum of Squares      Mean Square
    Error      27       995.10000000      36.85555556
\end{verbatim}}

Hence
\begin{equation*}
\text{dfe}=27,
\quad
\text{MSE}=36.85555556
\end{equation*}

The confidence interval for the mean of treatment A can be checked by typing the following into R.

{\scriptsize\begin{verbatim}
ybar = 5.3
n = 10
MSE = 36.85555556
dfe = 27
alpha = 0.05
SE = sqrt(MSE / n)
t = qt(1 - alpha/2, dfe) * SE
ybar - t
ybar + t
\end{verbatim}}

R prints the following results.

{\scriptsize\begin{verbatim}
[1] 1.360937
[1] 9.239063
\end{verbatim}}

The R results match the mean response table for treatment A.

{\scriptsize\begin{verbatim}
             TRT      N        Mean Y     95% CI MIN     95% CI MAX
             A       10      5.300000       1.360937       9.239063
\end{verbatim}}

\newpage

Let us take a closer look at the first line of the least significant difference table.

{\scriptsize\begin{verbatim}
                       Least Significant Difference Test

  TRT    TRT      Delta Y    95% CI MIN    95% CI MAX    t Value    Pr > |t|  
  A      B      -0.800000     -6.370677      4.770677      -0.29      0.7705  
\end{verbatim}}

The least significant difference of two treatment means $\bar y_A$ and $\bar y_B$ is
\begin{equation*}
\text{LSD}=t(1-\alpha/2,\text{dfe})\times\text{SE},
\quad
\text{SE}=\sqrt{\text{MSE}\times\left(\frac{1}{n_A}+\frac{1}{n_B}\right)}
\end{equation*}

The corresponding confidence interval is
\begin{equation*}
(\bar y_A-\bar y_B)\pm\text{LSD}
\end{equation*}

The confidence interval in the LSD table can be checked by typing the following into R.

{\scriptsize\begin{verbatim}
ybarA = 5.3
ybarB = 6.1
nA = 10
nB = 10
MSE = 36.85555556
dfe = 27
alpha = 0.05
SE = sqrt(MSE * (1/nA + 1/nB))
LSD = qt(1 - alpha/2, dfe) * SE
ybarA - ybarB - LSD
ybarA - ybarB + LSD
\end{verbatim}}

R prints the following results.

{\scriptsize\begin{verbatim}
[1] -6.370677
[1] 4.770677
\end{verbatim}}

The R results match the confidence interval in the LSD table.

{\scriptsize\begin{verbatim}
  TRT    TRT      Delta Y    95% CI MIN    95% CI MAX    t Value    Pr > |t|  
  A      B      -0.800000     -6.370677      4.770677      -0.29      0.7705  
\end{verbatim}}

\newpage

Let us take a closer look at the first line of the $t$-test table.

{\scriptsize\begin{verbatim}
                               Two Sample t-Test

  TRT    TRT      Delta Y    95% CI MIN    95% CI MAX    t Value    Pr > |t|  
  A      B      -0.800000     -5.922307      4.322307      -0.33      0.7466  
\end{verbatim}}

The $t$-test confidence interval is
\begin{equation*}
(\bar y_A-\bar y_B)\pm t(1-\alpha/2,\text{dfe})\times\text{SE}
\end{equation*}
where
\begin{equation*}
\text{SE}=\sqrt{\frac{\text{SSE}}{\text{dfe}}\times\left(\frac{1}{n_A}+\frac{1}{n_B}\right)},
\quad
\text{SSE}=\sum(y_A-\bar y_A)^2+\sum(y_B-\bar y_B)^2
\end{equation*}
and
\begin{equation*}
\text{dfe}=n_A+n_B-2
\end{equation*}

The confidence interval can be checked by typing the following into R.

{\scriptsize\begin{verbatim}
yA = c(6,0,2,8,11,4,13,1,8,0)
yB = c(0,2,3,1,18,4,14,9,1,9)
nA = length(yA)
nB = length(yB)
dfe = nA + nB - 2
SSE = var(yA) * (nA - 1) + var(yB) * (nB - 1)
MSE = SSE / dfe
SE = sqrt(MSE * (1/nA + 1/nB))
alpha = 0.05
t = qt(1 - alpha/2, dfe) * SE
mean(yA) - mean(yB) - t
mean(yA) - mean(yB) + t
\end{verbatim}}

R prints the following result which matches the above $t$-test table.

{\scriptsize\begin{verbatim}
[1] -5.922307
[1] 4.322307
\end{verbatim}}

R's $t$-test function gives the same result.

{\scriptsize\begin{verbatim}
t.test(yA,yB,var.equal=TRUE)

	Two Sample t-test

data:  yA and yB
t = -0.32812, df = 18, p-value = 0.7466
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -5.922307  4.322307
\end{verbatim}}

\end{document}
